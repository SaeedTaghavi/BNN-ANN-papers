# 脳の神経表現の再現（視覚）
脳の神経表現の理解は難しい。ニューラルネットワークに特定のタスクを学習（特定の損失関数に対して最適化）させると、脳の神経表現と同じ表現を獲得する場合がある。このとき、間接的に脳の神経表現の目的を知ることができる (Whyの解決手法)。ニューラルネットワークが一番成功したといってもいいのが視覚で、論文の数も多い。視覚の計算理論はDavid MarrのVisionから話を進めるべきだが、今回はニューラルネットワークが躍進してからの話に限定する。

## 視覚
### A. Krizhevsky, I. Sutskever, G. Hinton. "ImageNet classification with deep convolutional neural networks". *NIPS* (2012). ([pdf](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf))
まずはAlexNetから話を始める。CNNにImageNetデータセットの画像分類タスクを学習させると、CNNの畳み込みカーネルに一次視覚野(V1野)の単純細胞の受容野に似たパターン(様々な空間周波数の **ガボールフィルタ**)が現れた。なお、V1野の単純細胞の受容野がガボール関数で近似できることについては
JP. Jones, LA. Palmer. "An evaluation of the two-dimensional Gabor filter model of simple receptive fields in cat striate cortex". *J Neurophysiol.* **58**(6), 1233-58 (1987). ([pdf](http://www.neuro-it.net/pdf_dateien/summer_2004/Jones%201987.pdf))を参照。

---  
### D. Yamins, et al. "Performance-optimized hierarchical models predict neural responses in higher visual cortex". *PNAS.* **111**(23) 8619-8624 (2014). ([PNAS](https://www.pnas.org/content/111/23/8619))
AlexNetはニューラルネットワークでV1野が再現できることを示したが、この論文では下側頭皮質(IT野)まで畳み込みニューラルネットワークで再現可能であることを示した最初の論文である。特にこの論文でニューロンの活動とニューラルネットワークのユニットの活動の相関を表すために用いられた手法、**線形再構成法**(線形回帰法, linear regression methodology)は後の論文に影響を与えている。  

まずはどのようなニューラルネットワークのモデルを構築したかについて話をする。今はあまり話を聞かないが、この論文では **HMO**(hierarchical modular optimization)という手法によりモデルを構築している。基本的な考えはアンサンブル学習である。2043個のモデルを学習させて、それらを並列に組み合わせて1つの4層CNNモデルを構築した(Figure 2A)。これをHMOモデルと呼ぶ。　

学習後のHMOモデルに8種類のクラスに分類される画像シークエンスを見せたときの結果が(Figure 3a)である。IT野の3種類の場所について、IT野のニューロン群の活動（黒線）とNNの出力層の人工ニューロン群の活動（赤線）を比較している。この画像の見方だが、まずは真ん中の図(IT Site 56)に注目しよう。画像をよく見るとヒトの頭部の3Dモデルが背景内に浮かんでいることが分かる。ヒトの顔に応答するニューロンは顔が正面を向いているとよく発火するが、角度が付いていると発火は減少していることが分かる。   

ここから本題の線形再構成法((Figure 3A)における赤線の描き方)について説明する。脳内のあるニューロンの活動を完全に再現する1つの人工ニューロンが生まれれば比較は簡単である。しかし、実際にはニューロンが集団で機能を生み出しているため、2頭のサル間でも全く同じ応答を示すニューロンは生まれない。そこで、ニューラルネットワークの人工ニューロンの活動の線形結合により再構成する（要は線形回帰する）。すると、実際のニューロンの活動の分散の48.5±1.3%ほどを説明できた。

同じことをV4野についても行うと、HMOモデルの最後から2番目の第3層の活動の線形結合により、V4野のニューロンの活動がうまく近似できた(V4野のニューロンの活動の分散の51.7±2.3%が説明できた)。

まとめると、HMOモデルにおける第3層はV4野に、第4層（出力層）はIT野と相関したということである。この研究により、畳み込みニューラルネットワークは腹側視覚路のモデルとして妥当であることが示された。  

### S. Khaligh-Razavi, N. Kriegeskorte. "Deep supervised, but not unsupervised, models may explain IT cortical representation". *PLoS Comput. Biol*. **10**(11), (2014). ([PLoS](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003915))
IT野の活動の説明には教師あり学習したニューラルネットワークが適しているという論文。(Yamins et al. 2014)と主張は同じだが、示したいことが少し異なる。  

まず、(1)「ヒト」、(2)「サル」、(3)「これまでの視覚モデル(HMAX, VisNetなど)及び、記述子による特徴量(GIST, SIFTなど)」、(4)「画像分類タスクの教師あり学習したニューラルネットワーク」の4つについて、同じ画像セットを見せ、画像ごとの表現非類似度行列(representational dissimilarity matrix; **RDM**)を作成した。すると、これまでの視覚モデル(3)は生物/非生物の違いが区別できず、教師あり学習をしたニューラルネットワーク(4)の方がヒト(1)やサル(2)の視覚野のRDMと相関が高かった(相関はケンドールの順位相関係数で計算)。これにより視覚モデルにはニューラルネットワークを用いることが最適であることが明らかとなった。

---  
### I. Kuzovkin, et al. "Activations of Deep Convolutional Neural Network are Aligned with Gamma Band Activity of Human Visual Cortex". *Commun. Biol.* **1** (2018). ([Commun. Biol.](https://www.nature.com/articles/s42003-018-0110-y))
画像分類タスクを遂行するニューラルネットワークの活動は、視覚処理をするときのヒトの脳活動の **ガンマ帯域** (Gamma Band:30-150Hz)と一致することを示した論文。よく読むと、かなり大規模な研究であることが分かる。なんと100人の被験者に頭蓋内電極を埋め込んで脳活動を記録(intracranial depth recordings from 100 patients)したそうだ。ただ「2009年から計測を開始した」とあるので、恐らく他の研究で用いたデータを流用したのだろう。  

本題に入る。知りたいのは「視覚野のガンマ帯域の活動は物体認識において重要である」ということが正しいかどうかである。もし物体認識を行うニューラルネットワークの活動が他の帯域に比べてガンマ帯域とよく一致すれば、この仮説の妥当性が示せるということだ。  
手順はStep1から5まである(Figure 1)。全体的な流れとして、250枚の画像を被験者と学習済みのニューラルネットワーク(AlexNet)に見せ、そのときの活動を比較する。  
- **Step1** : 被験者の脳に11,293個の電極を埋め込み、それぞれの電極で画像を見せたときのLFP(局所フィールド電位)を記録した。ある画像に対するLFPと他の画像を見せた時のLFP間の距離を計算し、250×250の表現非類似度行列(RDM)を作った。  
- **Step2** : 画像分類タスクを学習済みのニューラルネットワーク(AlexNet)に250枚の画像を見せ、各層ごとに画像間のRDMを作った（RDMは全て250×250の行列）。  
- **Step3** : Step1で作ったRDMをランダムにシャッフルした行列を10,000個作成した。  
- **Step4** : 各電極のMNI座標をブロードマンの領野に対応させた（図はブロードマン19野）。  
- **Step5** : 「Step1で作った脳のRDM」と「Step2で作ったDNNのRDM」の相関係数、および「Step3で作ったシャッフルしたRDM」と「Step2で作ったDNNのRDM」の相関係数を計算した。正しいRDMとDNNのRDMの相関係数が、シャッフルされたRDMとDNNのRDMの相関係数よりも有意(p<0.001)であれば、相関係数を「脳領野」対「ニューラルネットワークの層」行列に加算した。行列は領野内の電極の数で正規化された。こうして脳の領野とニューラルネットワークの層間の相関行列が作成できたということである。  

さて、AlexNetのうち、畳み込み層の活動はガンマ帯域に対して他の周波数領域よりも強く相関した(Figure 5)。ここで(Figure 5c)に注目しよう。色付きの丸が描かれているが、丸の大きさは活動の大きさを表し、色の濃さは発火の部位的特異度を表す。畳み込み層、特にConv2, 3, 4はガンマ帯域特異的であることが分かる。逆に入力画像や線形層(全結合層)では、ガンマ帯域は特異的ではない。  

こうして、視覚野の活動において、物体認識をするニューラルネットワーク(AlexNet)と活動が相関する周波数範囲がガンマ帯域（特に低ガンマ(31-70Hz)）であることが分かった。再現というよりも、脳活動の機能をニューラルネットワークを通して間接的に知ることができたということである。  

---  
### M. Schrimpf, et al. "Brain-Score: Which Artificial Neural Network for Object Recognition is most Brain-Like?". (2018). ([bioRxiv](https://www.biorxiv.org/content/early/2018/09/05/407007))
画像分類タスクのモデルは多種多様なものが考案された。それでは視覚野の活動を最も再現しているモデル、つまり脳に近いモデルは何であろうか？この論文ではニューラルネットワークのモデルの活動と脳の活動の相関を表す指標、 **Brain-Score** を提案している。Brain-ScoreはV4野またはIT野のニューロンの活動とニューラルネットワークのモデルの相関(V4 or IT neural predictivity)、及び出力の画像分類の相関(behavioral predictivity)の3つの値の平均値として定義される。相関の計算に関しては(Yamins et al. 2014)の手法とほぼ同じように線形再構成法を用いている。  

様々なモデルのBrain-Scoreは(Figure 1, Table 1)のようになった。Brain-Scoreが最も高いのはDensenet-169であった。単に画像分類タスクの精度が高ければ脳に近いというわけではないという訳である。精度重視ではなく、このBrain-Score重視でモデルを組んでみるのも面白いかもしれない。

---  
### E. Kim, D. Hannan, G. Kenyon. "Deep Sparse Coding for Invariant Multimodal Halle Berry Neurons". *CVPR.* (2018). ([arxiv](https://arxiv.org/abs/1711.07998))
おばあさん細胞とは、「おばあさん」という概念に応答する（という想定の）ニューロン（群）である。おばあさん細胞の例として女優のHalle Berryの顔の写真にも文字にも応答するニューロンが2005年に発見された（参考：[A Halle Berry Brain Cell](http://www.caltech.edu/news/single-cell-recognition-halle-berry-brain-cell-1013)）。Halle Belly 細胞が他の女優に応答しないのかというのは論議があるそうだが、この論文ではスパースコーディングでHalle Berryニューロンが生じることを示した。  

モデルの基本は、顔画像と名前の画像を再構成するマルチタスクのオートエンコーダである(Figure 1)。ただし、正則化、側方抑制やフィードバックなどをモデル中に取り入れている。学習の結果、中間層にHalle Berryの顔画像と名前の画像によく応答するニューロンが現れた(Figure 8)。

---  
ここまで、ニューラルネットワークにおけるV1野からIT野までの再現について説明してきた。しかし、AlexNetが視覚経路に対応するならば、その初めの層がV1野と対応するのはおかしくないだろうか。というのも視覚経路はV1野にいたるまでに神経節細胞、LGNがあり、それらの受容野は同心円状(center-surrounding)なものであるからだ。AlexNetの第1層で見られるようなガボールフィルタとは異なる。同心円状の受容野は生じないのか？次の論文はそれに答えたもの（手法がどちらも特殊で、あまり十分に読めていないので、間違っている可能性大）。
### S. Ocko, J. Lindsey, S. Ganguli, S. Deny. "The emergence of multiple retinal cell types through efficient coding of natural movies". (2018). ([bioRxiv](https://www.biorxiv.org/content/early/2018/10/31/458737))
網膜神経節細胞には大きく2種類あり、大型のパラソル細胞(parasol, M型)と小型のミジェット細胞(midget, P型)がある。他にはK型(koniocellular)神経節細胞もあるが、この後の話に関わらない。要は受容野の大きさが異なる2種の細胞が自然画像をコードしている。これはストライドの異なる2種の畳み込み層を有することと同じである。  

もちろんメリット自体は生理学の本にはちゃんと書かれており、パラソル細胞は高速で大まかな物体の運動を検出するのに役立っている。ミジェット細胞は低速だが解像度が高く、物体の形を検出するのに役立っている。つまり、パラソル細胞は低い周波数成分を、ミジェット細胞は高い周波数成分を担当しているといえる。それぞれが得意分野を担当することで、1つのストライドしか持たない畳み込みよりも効率よく符号化できるそうだ(Figure 1)。

思った以上に手法が込み入っているので詳細な解説は伏せるが、シミュレーションの結果、網膜神経節細胞に似た受容野が獲得された(Figure 4,8)。  

### Q. Yan, et al. "Revealing Fine Structures of the Retinal Receptive Field by Deep Learning Networks". (2018). ([arxiv](https://arxiv.org/abs/1811.02290))
上のアプローチとは異なる。ホワイトノイズ画像を網膜神経節細胞に"見せ"、その発火パターン(spike train)を教師信号、ホワイトノイズ画像を入力として畳み込みニューラルネットワークを学習させると、畳み込みカーネルに神経節細胞に似た受容野が獲得されたという論文。  
